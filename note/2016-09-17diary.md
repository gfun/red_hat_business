# 9.17 work list


### -analysis features with pandas reference this [kernel](https://www.kaggle.com/yassinealouini/predicting-red-hat-business-value/features-processing/code).
1.plot with matplotlib and seaborn to deal with the [category features](https://stanford.edu/~mwaskom/software/seaborn/tutorial/categorical.html)

2.extract features using pandas with two new function: [assign](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.assign.html) and [pipe](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.pipe.html#pandas.Series.pipe). 
	
  -deal with train and test activities feature
  
    	-date extract year, month and day
    	
        -char_* range(1,11) lstrip('type ').astype(np.int32)
        
  -people features
  
    	-group_1 lstrip("group_1").astype(np.int32)
    	
        -char_* range(1,10) to int
        
        -char_* range(11,39) is bool to int
        
  -merge people

  -features
    	activity_category, group_1, date, month, year, day, 6
    	
        peopel:char_* 38
        
        activities: char_* 10
        
        totall features:54
        

### -train a simple xgboost model reference this [kernel](https://www.kaggle.com/abriosi/predicting-red-hat-business-value/raddar-0-98-xgboost-sparse-matrix-python).

### -3-5 [Algorithms](https://leetcode.com/)
	
   - Linked List Random Node:
   
   1.1/n = 1*(1-1/2)*(1-1/3)...(1-1/n)
		
        
   	if random.randint(0,index) is 0:
    	result = node
    	node = node.next
    	index+=1
     
   2.

### -reference:
		
  -anlysis with pandas [blog](https://tomaugspurger.github.io/)
        
  -xgboost [parameters](https://github.com/dmlc/xgboost/blob/master/doc/parameter.md) doc





Enter text in [Markdown](http://daringfireball.net/projects/markdown/). Use the toolbar above, or click the **?** button for formatting help.
